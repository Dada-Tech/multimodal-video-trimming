{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dada-Tech/multimodal-video-trimming/blob/main/MultiModal_Video_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "s_ZODmwejFil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "cGAcGf9yJ9Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "notebook_mode = \"auto\"\n",
        "colab_mode = True # for special requirements.txt without numpy/pandas\n",
        "\n",
        "# Check for Notebook mode\n",
        "notebook_mode = (True if 'COLAB_GPU' in os.environ else False) if notebook_mode == \"auto\" else notebook_mode\n",
        "\n",
        "print(f\"\"\"Notebook Mode: {notebook_mode}\"\"\")"
      ],
      "metadata": {
        "id": "PgpOalE1JhOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_section(message):\n",
        "  \"\"\"Prints a section separator with a custom message embedded.\n",
        "\n",
        "  Args:\n",
        "    message: The message to embed within the separator.\n",
        "  \"\"\"\n",
        "  separator_length = 40\n",
        "  separator_char = \"=\"\n",
        "\n",
        "  # Calculate padding for the message\n",
        "  message_length = len(message)\n",
        "  padding = (separator_length - message_length - 2) // 2\n",
        "  padding = max(padding, 0)\n",
        "\n",
        "  # Separator line\n",
        "  top_line = separator_char * separator_length\n",
        "\n",
        "  # Message line\n",
        "  message_line = separator_char * padding + \" \" + message + \" \" + separator_char * padding\n",
        "  if len(message_line) == 39:\n",
        "    message_line += separator_char\n",
        "  message_line = message_line[:separator_length]\n",
        "\n",
        "  print(top_line)\n",
        "  print(message_line)\n",
        "  print(top_line,'\\n')\n",
        "\n",
        "\n",
        "def print_info(message, preview = None, max_length=80):\n",
        "  print(f\"\"\"\\n=== {message}\\n\"\"\")\n",
        "  if preview:\n",
        "    print(\"--- Preview:\")\n",
        "    print(preview[:max_length] + \"...\" if len(preview) > max_length else preview)\n",
        "\n",
        "\n",
        "def notebook_mode_print(message_or_df):\n",
        "  if notebook_mode:\n",
        "    display(message_or_df) if isinstance(message_or_df, pd.DataFrame) else print(message_or_df)\n",
        "\n",
        "def ts_to_s(timestamp):\n",
        "    \"\"\"Converts a timestamp string in HH:MM:SS.mmm format to seconds.\n",
        "\n",
        "    Args:\n",
        "        timestamp: The timestamp string in HH:MM:SS.mmm format.\n",
        "\n",
        "    Returns:\n",
        "        The timestamp in seconds as a float.\n",
        "    \"\"\"\n",
        "    hours, minutes, seconds_milliseconds = re.split(r':', timestamp)\n",
        "    seconds, milliseconds = seconds_milliseconds.split('.')\n",
        "\n",
        "    # Convert to seconds\n",
        "    total_seconds = int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(milliseconds) / 1000.0\n",
        "\n",
        "    return total_seconds\n",
        "\n",
        "\n",
        "def generate_experiment_filename(id_token, base, filename_without_extension, extension):\n",
        "  m1w = hyperparameters[\"metric_1\"][\"weight\"]\n",
        "  m2w = hyperparameters[\"metric_2\"][\"weight\"]\n",
        "  mdt = hyperparameters[\"deletion_metric\"][\"threshold\"]\n",
        "\n",
        "  experiment_name = f\"_m1w-{m1w}_m2w-{m2w}_mdt-{mdt}_{id_token}\"\n",
        "  return os.path.join(base, filename_without_extension + experiment_name + \".\" + extension)\n",
        "\n",
        "\n",
        "# Define the function to count words while removing punctuation\n",
        "def count_words_without_punctuation(sentence):\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Filter out punctuation\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "    return len(words)"
      ],
      "metadata": {
        "id": "kgrOYTpSaJQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation & Setup"
      ],
      "metadata": {
        "id": "bvF2LUKURqhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if notebook_mode:\n",
        "    print_section(\"installing deps\")\n",
        "\n",
        "    requirements_txt = \"requirements-colab.txt\" if colab_mode else \"requirements.txt\"\n",
        "\n",
        "    # download requirements.txt from repository\n",
        "    subprocess.run([\"curl\", \"-O\", \"https://raw.githubusercontent.com/Dada-Tech/multimodal-video-trimming/main/\" + requirements_txt], check=True)\n",
        "\n",
        "    subprocess.check_call(['python', '-m', 'pip', 'install', '--no-cache-dir', '-r', requirements_txt])\n",
        "\n",
        "    print_info(\"installation done.\")\n",
        "else:\n",
        "    print_info(\"skipping installation\")"
      ],
      "metadata": {
        "id": "AU5l60Zwt93f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, validator, conint, confloat, ValidationError\n",
        "from enum import Enum\n",
        "import argparse\n",
        "\n",
        "class AutoSummary(BaseModel):\n",
        "    summary_length_percentage: confloat(ge=0.2, le=0.5)\n",
        "    min_summary_length: conint(ge=30, le=60)\n",
        "    max_summary_length: conint(ge=100, le=3000)\n",
        "\n",
        "class DeletionMetric(BaseModel):\n",
        "    threshold: confloat(ge=0.05, le=0.5)\n",
        "\n",
        "class Metric1(BaseModel):\n",
        "    model_size: str\n",
        "    weight: confloat(ge=0, le=1.0)\n",
        "    min_words: conint(ge=50, le=1000)\n",
        "\n",
        "class Metric2(BaseModel):\n",
        "    weight: confloat(ge=0, le=1.0)\n",
        "    min_scene_len: conint(ge=15, le=9000)\n",
        "    threshold: conint(ge=10, le=50)\n",
        "\n",
        "class Hyperparameters(BaseModel):\n",
        "    auto_summary: AutoSummary\n",
        "    deletion_metric: DeletionMetric\n",
        "    metric_1: Metric1\n",
        "    metric_2: Metric2  # Add Metric2 with constraints"
      ],
      "metadata": {
        "id": "qRzBv6xTL2In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs & Hyperparameters\n",
        "\n",
        "### Auto Summary\n",
        "\n",
        "*   **`summary_length_percentage`**: 0.3\n",
        "    *   Determines the target length of the summary as a percentage of the original text length.\n",
        "*   **`min_summary_length`**: 30\n",
        "    *   Sets the minimum number of words (or tokens) allowed in the summary.\n",
        "*   **`max_summary_length`**: 600\n",
        "    *   Sets the maximum number of words (or tokens) allowed in the summary.\n",
        "\n",
        "### Deletion Metric\n",
        "\n",
        "*   **`threshold`**: 0.3\n",
        "    *   Deleting the bottom **`n`** percent of scores.\n",
        "\n",
        "### Metric 1\n",
        "*   **`weight`**: Values between `0` and `1.0`\n",
        "    *   Controls the influence of this metric on the final score\n",
        "*   **`model_size`**: either `base` or `large`\n",
        "    *   Controls which model used for text tasks for this metric.\n",
        "*   **`min_words`**: minimum number of words for this\n",
        " metric to be used. Prevents this text-based metric from being used on cinematic type videos.\n",
        "\n",
        "### Metric 2\n",
        "\n",
        "*   **`weight`**: Values between `0` and `1.0`\n",
        "    *   Controls the influence of this metric on the final score\n",
        "*   **`min_scene_len`**: Values between `15` and `9000`\n",
        "    *   Defines the minimum number of frames required for a scene to be considered.\n",
        "    *   Ensures scenes are at least half a second long (15 frames) and at most 5 minutes (9000 frames at 30fps).\n",
        "*   **`threshold`**: Values between `10` and `50`\n",
        "    *   Sets the sensitivity for scene detection.\n",
        "    *   Lower values detect more cuts, while higher values make detection stricter."
      ],
      "metadata": {
        "id": "W1CG4tXznFQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if notebook_mode:\n",
        "  video_input = \"dataset/teamwork in the classroom.mov\"\n",
        "  video_output = \"dataset/teamwork in the classroom_skimmed.mov\"\n",
        "\n",
        "  # video_input = \"dataset/uGu_10sucQo.mp4\"\n",
        "  # video_output = \"dataset/uGu_10sucQo_skimmed.mp4\"\n",
        "\n",
        "  experiment_mode = False ## If experiment mode is True, you must run SRT File Gen block\n",
        "  skip_nlp_downloads = False\n",
        "\n",
        "  export_original_text = False\n",
        "  export_trimmed_text = False\n",
        "  export_summarized_text = False\n",
        "\n",
        "  video_export_max_length_seconds = 0 # set develop video max length to export a shortened version of the multimedia\n",
        "\n",
        "  # original was max_length=150, min_length=30\n",
        "  hyperparameters = {\n",
        "      \"auto_summary\": {\n",
        "        \"summary_length_percentage\": 0.3,\n",
        "        \"min_summary_length\": 30,\n",
        "        \"max_summary_length\": 600\n",
        "      },\n",
        "      \"deletion_metric\": {\n",
        "          \"threshold\": 0.2\n",
        "      },\n",
        "      \"metric_1\": {\n",
        "          \"model_size\": \"base\",\n",
        "          \"weight\": 1,\n",
        "          \"min_words\": 50\n",
        "      },\n",
        "      \"metric_2\": {\n",
        "          \"weight\": 0.3,\n",
        "          \"min_scene_len\": 15,\n",
        "          \"threshold\": 25\n",
        "      }\n",
        "  }\n",
        "\n",
        "else:\n",
        "  # Define the argparse parser\n",
        "  parser = argparse.ArgumentParser(description=\"Process video and hyperparameters.\")\n",
        "\n",
        "  # Define the arguments for the inputs\n",
        "  parser.add_argument(\"--video_input\", \"-i\", type=str, required=True, help=\"Path to the video input file\")\n",
        "  parser.add_argument(\"--video_output\", \"-o\", type=str, default=None, help=\"Path to save the output video\")\n",
        "  parser.add_argument(\"--experiment_mode\", \"-exp\", action=\"store_true\", help=\"Run the project in experiment mode. (No video exports, just timestamps)\")\n",
        "  parser.add_argument(\"--video_export_max_length_seconds\", type=int, default=0, help=\"Maximum length of the video to export (in seconds)\")\n",
        "  parser.add_argument(\"--export_original_text\", action=\"store_true\", help=\"Export original text (from video)\")\n",
        "  parser.add_argument(\"--export_trimmed_text\", action=\"store_true\", help=\"Export trimmed text\")\n",
        "  parser.add_argument(\"--export_summarized_text\", action=\"store_true\", help=\"Export summarized text\")\n",
        "  parser.add_argument(\"--skip_nlp_downloads\", action=\"store_true\", help=\"skip nltk library downloads\")\n",
        "\n",
        "\n",
        "  # Hyperparameters as individual arguments\n",
        "  parser.add_argument(\"--auto_summary_summary_length_percentage\", type=float, default=0.3, help=\"Summary length as a percentage\")\n",
        "  parser.add_argument(\"--auto_summary_min_summary_length\", type=int, default=30, help=\"Minimum summary length\")\n",
        "  parser.add_argument(\"--auto_summary_max_summary_length\", type=int, default=600, help=\"Maximum summary length\")\n",
        "\n",
        "  parser.add_argument(\"--deletion_metric_threshold\", type=float, default=0.2, help=\"Threshold for deletion metric\")\n",
        "\n",
        "  parser.add_argument(\"--metric_1_model_size\", type=str, choices=[\"base\", \"large\"], default=\"base\", help=\"Model size for metric 1\")\n",
        "  parser.add_argument(\"--metric_1_weight\", type=float, default=1.0, help=\"Weight for metric 1 (contribution to final score)\")\n",
        "  parser.add_argument(\"--metric_1_min_words\", type=int, default=50, help=\"Minimum number of words to determine this metric applicable\")\n",
        "\n",
        "  parser.add_argument(\"--metric_2_weight\", type=float, default=0.3, help=\"Weight for metric 2 (contribution to final score)\")\n",
        "  parser.add_argument(\"--metric_2_min_scene_len\", type=int, default=15, help=\"Minimum scene length for metric 2\")\n",
        "  parser.add_argument(\"--metric_2_threshold\", type=int, default=25, help=\"Threshold for scene detection for metric 2\")\n",
        "\n",
        "  # Parse arguments\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  # Now you can use the parsed arguments\n",
        "  video_input = args.video_input\n",
        "  experiment_mode = args.experiment_mode\n",
        "  skip_nlp_downloads = args.skip_nlp_downloads\n",
        "  video_export_max_length_seconds = args.video_export_max_length_seconds\n",
        "  video_output = args.video_output\n",
        "  export_original_text = args.export_original_text\n",
        "  export_trimmed_text = args.export_trimmed_text\n",
        "  export_summarized_text = args.export_summarized_text\n",
        "\n",
        "  hyperparameters = {\n",
        "      \"auto_summary\": {\n",
        "          \"summary_length_percentage\": args.auto_summary_summary_length_percentage,\n",
        "          \"min_summary_length\": args.auto_summary_min_summary_length,\n",
        "          \"max_summary_length\": args.auto_summary_max_summary_length\n",
        "      },\n",
        "      \"deletion_metric\": {\n",
        "          \"threshold\": args.deletion_metric_threshold\n",
        "      },\n",
        "      \"metric_1\": {\n",
        "          \"model_size\": args.metric_1_model_size,\n",
        "          \"weight\": args.metric_1_weight,\n",
        "          \"min_words\": args.metric_1_min_words\n",
        "      },\n",
        "      \"metric_2\": {\n",
        "          \"weight\": args.metric_2_weight,\n",
        "          \"min_scene_len\": args.metric_2_min_scene_len,\n",
        "          \"threshold\": args.metric_2_threshold\n",
        "      }\n",
        "  }\n",
        "\n",
        "if experiment_mode:\n",
        "  print_section(\"Experiment Mode\")\n",
        "\n",
        "# Validate Hyperparameters\n",
        "try:\n",
        "    validated_hyperparameters = Hyperparameters(**hyperparameters)\n",
        "except ValidationError as e:\n",
        "    print(f\"Hyperparameter validation error: {e}\")\n",
        "\n",
        "    print_info(\"exiting...\")\n",
        "    os._exit(1)"
      ],
      "metadata": {
        "id": "igRwpQDqdJJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "lMg0H4TIoMYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_info(\"importing...\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import gdown\n",
        "import re\n",
        "from functools import reduce\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "# ML General\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn.functional as F\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Text\n",
        "import string\n",
        "import pytextrank\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import spacy\n",
        "import srt\n",
        "\n",
        "# Audio\n",
        "import whisperx\n",
        "import silero_vad\n",
        "from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Video\n",
        "import ffmpeg\n",
        "from scenedetect import detect, ContentDetector\n",
        "\n",
        "print_info(\"importing done\")"
      ],
      "metadata": {
        "id": "oiFdk6oSYg8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_nlp_downloads:\n",
        "  print_info(\"downloading NLTK libraries...\")\n",
        "\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('punkt_tab')\n",
        "\n",
        "  # Load the spaCy model\n",
        "  spacy.cli.download(\"en_core_web_sm\")\n",
        "  sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "  print_info(\"downloading done\")"
      ],
      "metadata": {
        "id": "Utzxa9w-TvLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "LYkbiBtust3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_base = os.path.dirname(video_input)\n",
        "path_dataset = full_base\n",
        "filename = os.path.basename(video_input)\n",
        "filename_without_extension = os.path.splitext(filename)[0]\n",
        "filename_video_extension = video = os.path.splitext(video_input)[1]\n",
        "\n",
        "# Video Input\n",
        "filename_video_input = filename\n",
        "\n",
        "# Output Filenames\n",
        "filename_subtitles_output = filename_without_extension + \".srt\"\n",
        "filename_audio_output = filename_without_extension + \".wav\"\n",
        "filename_audio_output_skimmed = filename_without_extension + \"_skimmed.wav\"\n",
        "\n",
        "# Text Output Filenmes\n",
        "filename_paragraph_original = os.path.join(full_base, filename_without_extension + \"_paragraph_original.txt\")\n",
        "filename_paragraph_trimmed = os.path.join(full_base, filename_without_extension + \"_paragraph_trimmed.txt\")\n",
        "filename_paragraph_summarized = os.path.join(full_base, filename_without_extension + \"_paragraph_summarized.txt\")\n",
        "\n",
        "# Experiment CSV\n",
        "filename_experiment_sentences = generate_experiment_filename(\"sentences\", full_base, filename_without_extension, \"csv\")\n",
        "filename_experiment_hyperparameters = generate_experiment_filename(\"hyperparameters\", full_base, filename_without_extension, \"json\")\n",
        "\n",
        "# Output\n",
        "subtitles_output = os.path.join(full_base, filename_subtitles_output)\n",
        "audio_output = os.path.join(full_base, filename_audio_output)\n",
        "audio_output_skimmed = os.path.join(full_base, filename_audio_output_skimmed)\n",
        "\n",
        "if video_output:\n",
        "  filename_video_output_skimmed = os.path.basename(video_output)\n",
        "  video_output_skimmed = video_output\n",
        "else:\n",
        "  filename_video_output_skimmed = filename_without_extension + \"_skimmed\" + filename_video_extension\n",
        "  video_output_skimmed = os.path.join(full_base, filename_video_output_skimmed)\n",
        "\n",
        "video = ''\n",
        "audio = ''\n",
        "subtitles = ''\n",
        "sentences = ''"
      ],
      "metadata": {
        "id": "5qOwE-2vstJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "Ix3Qgzz84Cg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_if_exists(df, col_name):\n",
        "  \"\"\"Drops a column from a DataFrame if it exists\n",
        "  Args:\n",
        "    df: The pandas DataFrame to modify.\n",
        "    col_name: The name of the column to drop and insert.\n",
        "  \"\"\"\n",
        "  if col_name in df.columns:\n",
        "    df.drop(col_name, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "3zQrvh2r1b6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paragraph_to_file(text, filename):\n",
        "    try:\n",
        "        # Process the text with spaCy to split into sentences\n",
        "        doc = sp(text)\n",
        "\n",
        "        sentences = [sent.text.strip() for sent in doc.sents]\n",
        "\n",
        "        # Write each sentence to the file\n",
        "        with open(filename, 'w') as file:\n",
        "            for sentence in sentences:\n",
        "                file.write(sentence + \"\\n\")\n",
        "\n",
        "        print(f\"Export Successful: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "BDIu2_mA5lBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "\n",
        "- teamwork in the classroom.mov - `190MB`\n",
        "- flipped learning basics.mov - `380MB`\n",
        "- assessing students without exams.mov - `830MB`"
      ],
      "metadata": {
        "id": "0E33VpXsRdq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if notebook_mode:\n",
        "  from google.colab import files\n",
        "\n",
        "  # Google Drive Dataset Location\n",
        "  folder_id = '1k7DLJPl1xz9lpU4l3dZYtPe1XawhrXeC' # taken from drive.google.com/drive/u/1/folders/1k7D...(this part)\n",
        "  gdown.download_folder(id=folder_id, quiet=False, use_cookies=False)"
      ],
      "metadata": {
        "id": "G3N4G0ODPvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing - Audio"
      ],
      "metadata": {
        "id": "7dsF0AmX2pt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_section(\"Preprocessing\")"
      ],
      "metadata": {
        "id": "LCBy6FK_G0Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio - Extract"
      ],
      "metadata": {
        "id": "_zukAoWW7Ia0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio (wav) from video\n",
        "# !ffmpeg -y -i \"$video_input\" -vn -acodec pcm_s16le -ar 44100 -ac 2 \"$audio_output\"\n",
        "print_info(\"extracting audio from video\")\n",
        "\n",
        "subprocess.run(['ffmpeg', '-y', '-i', video_input, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', audio_output], check=True)\n",
        "# subprocess.run([\"ffmpeg\", '-y', '-i', video_input, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', audio_output], check=True, capture_output=True)"
      ],
      "metadata": {
        "id": "N_E3vUnK7GYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio - SRT File Generation"
      ],
      "metadata": {
        "id": "-aWRBu9h7XkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Time Taken: ~4min"
      ],
      "metadata": {
        "id": "p9DVWtXh79zY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRT  \n",
        "each **`subtitle`** in the subtitles array has the following properties:\n",
        "\n",
        "1. **`index`**\n",
        "   - The sequential number of the subtitle within the SRT file.\n",
        "   - `1`, `2`, `3`, etc. (Integer)\n",
        "2. **`start`**\n",
        "   - The time (in milliseconds) when the subtitle should appear on the screen.\n",
        "   - `00:00:05,000` (String representing HH:MM:SS,SSS)\n",
        "3. **`end`**\n",
        "   - The time (in milliseconds) when the subtitle should disappear from the screen.\n",
        "   - `00:00:10,000` (String representing HH:MM:SS,SSS)\n",
        "4. **`content`**\n",
        "   - The actual text of the subtitle that will be displayed.\n",
        "   - \"Hello, world!\" (String)\n",
        "5. **`proprietary`**\n",
        "   - This field holds any additional data or formatting specific to the SRT file or software used to create it. Often empty and can usually be ignored.\n",
        "   - `''` (Empty string, or sometimes contains specific formatting codes)"
      ],
      "metadata": {
        "id": "tCtO9Rg6J5Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seconds_to_srt_timestamp(seconds):\n",
        "    \"\"\"\n",
        "    Extract hours, minutes, seconds, and milliseconds\n",
        "    from a given number of seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = seconds % 60\n",
        "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "\n",
        "    # Format as HH:MM:SS,MS\n",
        "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\""
      ],
      "metadata": {
        "id": "cn5g2bA470bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select device (GPU if available, otherwise CPU)\n",
        "language=\"en\"\n",
        "\n",
        "from multiprocessing import Queue\n",
        "\n",
        "# GPU\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "  compute_type = \"float32\"\n",
        "  batch_size = 16\n",
        "  model_whisperx = \"base\"\n",
        "\n",
        "  print_info(f\"\"\"Generating SRT File with {device}...\"\"\")\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "  compute_type = \"int8\"\n",
        "  batch_size = 1\n",
        "  model_whisperx = \"tiny\"\n",
        "\n",
        "  queue = Queue(maxsize=200)\n",
        "\n",
        "  print_info(f\"\"\"WARNING: Generating SRT File with {device}...\"\"\")\n",
        "\n",
        "\n",
        "# Model WhisperX\n",
        "model = whisperx.load_model(model_whisperx, device=device, language=language, compute_type=compute_type) # Choose \"base\" or \"large\" model\n",
        "\n",
        "# Transcribe audio\n",
        "aligned_segments = model.transcribe(audio_output, batch_size=batch_size)\n",
        "\n",
        "# Align with forced alignment\n",
        "alignment_model, metadata = whisperx.load_align_model(language_code=aligned_segments[\"language\"], device=device)\n",
        "aligned_segments = whisperx.align(aligned_segments[\"segments\"], alignment_model, metadata, audio_output, device)\n",
        "\n",
        "if not experiment_mode:\n",
        "  # Generate SRT file with aligned sentences\n",
        "  with open(subtitles_output, \"w\") as f:\n",
        "      for i, segment in enumerate(aligned_segments[\"segments\"], 1):\n",
        "          # Get start and end times in SRT format\n",
        "          start_time = seconds_to_srt_timestamp(segment[\"start\"])\n",
        "          end_time = seconds_to_srt_timestamp(segment[\"end\"])\n",
        "\n",
        "          # Write SRT entry\n",
        "          f.write(f\"{i}\\n{start_time} --> {end_time}\\n{segment['text']}\\n\\n\")\n",
        "\n",
        "  print_info(\"SRT file generated\", subtitles_output)\n",
        "else:\n",
        "  # Generate SRT content as a string\n",
        "  srt_content = \"\"\n",
        "  for i, segment in enumerate(aligned_segments[\"segments\"], 1):\n",
        "      # Get start and end times in SRT format\n",
        "      start_time = seconds_to_srt_timestamp(segment[\"start\"])\n",
        "      end_time = seconds_to_srt_timestamp(segment[\"end\"])\n",
        "\n",
        "      # Append SRT entry to the string\n",
        "      srt_content += f\"{i}\\n{start_time} --> {end_time}\\n{segment['text']}\\n\\n\"\n",
        "\n",
        "  # Parse the SRT content directly\n",
        "  subtitles = list(srt.parse(srt_content))"
      ],
      "metadata": {
        "id": "gG9mX-np7hl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing - Text"
      ],
      "metadata": {
        "id": "fngx77xelnQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text - Load SRT File"
      ],
      "metadata": {
        "id": "SdFY0zkntLX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not experiment_mode:\n",
        "  # Subtitles:\n",
        "  with open(subtitles_output, \"r\", encoding=\"utf-8\") as f:\n",
        "      subtitles = list(srt.parse(f.read()))"
      ],
      "metadata": {
        "id": "Te0w_n66zfWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text - Sentence Segmentation"
      ],
      "metadata": {
        "id": "Dgaty2bZ-4HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_timedelta(timedelta_obj):\n",
        "    \"\"\"Formats a datetime.timedelta object into HH:MM:SS.mmm timestamp.\n",
        "\n",
        "    Args:\n",
        "        timedelta_obj: The datetime.timedelta object.\n",
        "\n",
        "    Returns:\n",
        "        A string representing the timestamp in HH:MM:SS.mmm format.\n",
        "    \"\"\"\n",
        "    total_seconds = timedelta_obj.total_seconds()\n",
        "    hours = int(total_seconds // 3600)  # Get hours\n",
        "    minutes = int((total_seconds % 3600) // 60)  # Get minutes\n",
        "    seconds = int(total_seconds % 60)  # Get seconds\n",
        "    milliseconds = int((total_seconds % 1) * 1000)  # Get milliseconds\n",
        "\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}\""
      ],
      "metadata": {
        "id": "3zelhoRN-x-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for i, segment in enumerate(subtitles):\n",
        "    sentences.append({\n",
        "        'base_idx': i,\n",
        "        'start_time': format_timedelta(segment.start),\n",
        "        'end_time': format_timedelta(segment.end),\n",
        "        'sentence': segment.content\n",
        "    })\n",
        "\n",
        "df_sentences = pd.DataFrame(sentences, columns=['base_idx', 'start_time', 'end_time', 'sentence'])\n",
        "sentences = df_sentences['sentence'].tolist()\n",
        "notebook_mode_print(df_sentences)"
      ],
      "metadata": {
        "id": "5FVw_EqF-KZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text - Paragraph\n",
        "combination of all subtitle parts.  \n",
        "\n",
        "WhisperAI enhances transcription with basic punctuation."
      ],
      "metadata": {
        "id": "7vSt5ElqS2bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = reduce(lambda acc, seg: acc + seg.strip() + ' ', sentences, '')\n",
        "parahraph_wordcount = count_words_without_punctuation(paragraph)\n",
        "\n",
        "# Print the paragraph\n",
        "notebook_mode_print(paragraph)\n",
        "print(f\"paragraph word count: {parahraph_wordcount}\")\n",
        "print_info(\"paragraph sample\", paragraph)"
      ],
      "metadata": {
        "id": "OFMXfndjQPGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text - Paragraph Summarized"
      ],
      "metadata": {
        "id": "R-DIsC5NRn3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Time Taken: ~1min"
      ],
      "metadata": {
        "id": "VZSi_e-h0BLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_info(\"Summarizing Paragraph\")"
      ],
      "metadata": {
        "id": "dw38SZCWNv88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph_summarized = \"\"\n",
        "\n",
        "if parahraph_wordcount > 0:\n",
        "  # Model: Longformer Encoder-Decoder\n",
        "  model_name = \"allenai/led-base-16384\"\n",
        "  tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "  model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "  text = paragraph\n",
        "\n",
        "  # Tokenization\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", max_length=16384, truncation=True)\n",
        "\n",
        "  # Calculate dynamic summary length\n",
        "  summary_length_percentage = hyperparameters[\"auto_summary\"][\"summary_length_percentage\"]\n",
        "  min_summary_length = hyperparameters[\"auto_summary\"][\"min_summary_length\"]\n",
        "  max_summary_length = hyperparameters[\"auto_summary\"][\"max_summary_length\"]\n",
        "\n",
        "\n",
        "  input_length = len(inputs[\"input_ids\"][0])\n",
        "  summary_length = int(input_length * summary_length_percentage)\n",
        "  summary_length = max(min_summary_length, min(summary_length, max_summary_length))\n",
        "\n",
        "  # Summary Generation\n",
        "  summary_ids = model.generate(\n",
        "      inputs[\"input_ids\"],\n",
        "      max_length=summary_length,\n",
        "      min_length=min_summary_length,\n",
        "      length_penalty=1.2,\n",
        "      num_beams=4,\n",
        "      early_stopping=True\n",
        "  )\n",
        "\n",
        "  paragraph_summarized = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "  print_info(\"paragraph summarized\", paragraph_summarized)"
      ],
      "metadata": {
        "id": "9h82EUpYU1uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Metrics\n",
        "print_info(\"Simple Metrics\")\n",
        "\n",
        "original_length = len(paragraph)\n",
        "summary_length = len(paragraph_summarized)\n",
        "\n",
        "print(f\"original length: {original_length}\")\n",
        "print(f\"summary length: {summary_length}\")\n",
        "\n",
        "if original_length > 0 and original_length > summary_length:\n",
        "  summarization_ratio = (original_length - summary_length) / original_length\n",
        "  print(f\"Summarized/Original Length Ratio: {summarization_ratio:.2f}\")\n",
        "elif original_length == 0:\n",
        "  print_info(\"WARN: 0 Words found in video\")"
      ],
      "metadata": {
        "id": "83D8Px3ZZ25D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text"
      ],
      "metadata": {
        "id": "NqhKyoOO3voB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric 1: Sentence- Summarized Paragraph Relevancy (Cosine Similarity)"
      ],
      "metadata": {
        "id": "_8gMAZOaQKNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Time Taken: ~2min"
      ],
      "metadata": {
        "id": "FBhdvFmpM5wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_section(\"Metric 1: Sentence-Summarized Relevancy\")"
      ],
      "metadata": {
        "id": "zPqUIFW_UP4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if parahraph_wordcount < hyperparameters[\"metric_1\"][\"min_words\"]:\n",
        "  skip_text_metrics = True\n",
        "  print_info(f\"Warning: Video contained only {parahraph_wordcount} words, \\\n",
        "  which did not meet minimum wordcount threshold to use this metric. Skipping.\")\n",
        "\n",
        "else:\n",
        "  skip_text_metrics = False"
      ],
      "metadata": {
        "id": "9E9Op_5QHZxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_text_metrics:\n",
        "  # Model Setup\n",
        "  model_instructor_xl = SentenceTransformer(\n",
        "    'hkunlp/instructor-xl',\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  )"
      ],
      "metadata": {
        "id": "kGDOM_LzxmeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_text_metrics:\n",
        "  # 3: Embedding (with Tokenization)\n",
        "  paragraph_embedding = model_instructor_xl.encode(\n",
        "    paragraph_summarized,\n",
        "    convert_to_tensor=True,\n",
        "    max_length=4096,\n",
        "    truncation=True\n",
        "  )\n",
        "\n",
        "  sentence_embeddings = model_instructor_xl.encode(\n",
        "    sentences,\n",
        "    convert_to_tensor=True,\n",
        "    max_length=4096,\n",
        "    truncation=True\n",
        "  )"
      ],
      "metadata": {
        "id": "7gb_5XZGYIad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Explanation  \n",
        "The [CLS] (classification) token is often used in transformer models to represent the overall meaning or summary of the input sequence. By extracting its embedding, you're essentially obtaining a representation that captures the main point or essence of the paragraph."
      ],
      "metadata": {
        "id": "bBHu-QLj6kq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_text_metrics:\n",
        "  # 4: Relevance scores\n",
        "\n",
        "  relevance_scores = [\n",
        "    torch.cosine_similarity(paragraph_embedding, sentence_embedding, dim=0).item()\n",
        "    for sentence_embedding in sentence_embeddings\n",
        "  ]\n",
        "\n",
        "  # Normalization: min-max normalization\n",
        "  min_score = min(relevance_scores)\n",
        "  max_score = max(relevance_scores)\n",
        "  normalized_scores = [(score - min_score) / (max_score - min_score) for score in relevance_scores]\n",
        "\n",
        "  # round\n",
        "  normalized_scores = [np.format_float_positional(score, precision=2, unique=False, fractional=False, trim='k') for score in normalized_scores]"
      ],
      "metadata": {
        "id": "9BwrHjKc4Tge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: Display Results\n",
        "drop_if_exists(df_sentences, \"metric_1_score\")\n",
        "\n",
        "if not skip_text_metrics:\n",
        "  df_sentences.insert(0, \"metric_1_score\", normalized_scores)\n",
        "else:\n",
        "  df_sentences.insert(1, \"metric_1_score\", 0)\n",
        "\n",
        "notebook_mode_print(df_sentences)"
      ],
      "metadata": {
        "id": "CNLoAh9FWssQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Sheet for easy exporting\n",
        "# from google.colab import sheets\n",
        "# sheet = sheets.InteractiveSheet(df=df_sentences)"
      ],
      "metadata": {
        "id": "4hqkpxKs5zT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video"
      ],
      "metadata": {
        "id": "rJ-tgGS8Sr5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric 2: Shot Detection"
      ],
      "metadata": {
        "id": "U4v3Vfh3t0XY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Time taken ~1min"
      ],
      "metadata": {
        "id": "vDHZKa8dHeYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Detect Scenes\n",
        "\n",
        "scene_list = detect(video_input,\n",
        "                    ContentDetector(\n",
        "                        threshold=hyperparameters[\"metric_2\"][\"threshold\"],\n",
        "                        min_scene_len=hyperparameters[\"metric_2\"][\"min_scene_len\"]\n",
        "                    ))\n",
        "\n",
        "notebook_mode_print(scene_list)"
      ],
      "metadata": {
        "id": "AnIe3q7sBlwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2QLV855QHWWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2: Segment Scoring\n",
        "scene_segments = [(end.get_seconds() - start.get_seconds(), start.get_timecode(), end.get_timecode())\n",
        "                  for start, end in scene_list]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_scenes = pd.DataFrame(scene_segments, columns=[\"duration\", \"start_time\", \"end_time\"])\n",
        "\n",
        "total_duration = df_scenes[\"duration\"].sum()\n",
        "\n",
        "# Calculate score: row's duration / total duration - this is Normalization\n",
        "df_scenes[\"normalized_score\"] = df_scenes[\"duration\"] / total_duration\n",
        "df_scenes[\"normalized_score\"] = df_scenes[\"normalized_score\"].round(2)\n",
        "\n",
        "# Min-Max scaling\n",
        "df_scenes[\"score\"] = \\\n",
        " (df_scenes[\"normalized_score\"] - df_scenes[\"normalized_score\"].min()) / \\\n",
        "(df_scenes[\"normalized_score\"].max() - df_scenes[\"normalized_score\"].min())\n",
        "df_scenes[\"score\"] = df_scenes[\"score\"].round(2)\n",
        "\n",
        "notebook_mode_print(df_scenes)"
      ],
      "metadata": {
        "id": "tUw7Ao5L6pKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute weighted scene score for each sentence\n",
        "def compute_sentence_score(sentence_row):\n",
        "    total_score = 0\n",
        "    scene_number_start = -1\n",
        "    scene_number_end = -1\n",
        "    sentence_start = ts_to_s(sentence_row['start_time'])\n",
        "    sentence_end = ts_to_s(sentence_row['end_time'])\n",
        "    sentence_duration = sentence_end - sentence_start\n",
        "\n",
        "    # find scene start and corresponding index\n",
        "    for scene_idx, scene_row in df_scenes.iterrows():\n",
        "      scene_score = scene_row['score']\n",
        "      scene_start = ts_to_s(scene_row['start_time'])\n",
        "      scene_end = ts_to_s(scene_row['end_time'])\n",
        "      scene_duration = scene_row['duration']\n",
        "\n",
        "      # case 1: Fully contained\n",
        "      if sentence_start >= scene_start and sentence_end <= scene_end:\n",
        "        scene_number_start = scene_idx\n",
        "        scene_number_end = scene_idx\n",
        "\n",
        "        total_score = scene_score\n",
        "        break\n",
        "\n",
        "      # case 2: start-contained, end extends\n",
        "      elif sentence_start >= scene_start and sentence_start < scene_end and sentence_end >= scene_end:\n",
        "        scene_number_start = scene_idx\n",
        "\n",
        "        percentage = (scene_end - sentence_start) / sentence_duration\n",
        "        total_score += scene_score * percentage\n",
        "\n",
        "      # case 3: end-contained, start extends\n",
        "      elif sentence_start <= scene_start and sentence_end <= scene_end and sentence_end > scene_start:\n",
        "        scene_number_end = scene_idx\n",
        "\n",
        "        percentage = (sentence_end - scene_start) / sentence_duration\n",
        "        total_score += scene_score * percentage\n",
        "\n",
        "      # case 4: mid part\n",
        "      elif sentence_start <= scene_start and sentence_end >= scene_end:\n",
        "        percentage = scene_duration / sentence_duration\n",
        "        total_score += scene_score * percentage\n",
        "\n",
        "    return total_score,scene_number_start,scene_number_end"
      ],
      "metadata": {
        "id": "PqIgkBXemwYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3: Apply score to contained sentence and track scene_number\n",
        "\n",
        "# Drop existing columns if needed\n",
        "drop_if_exists(df_sentences, \"metric_2_score\")\n",
        "drop_if_exists(df_sentences, \"scene_number_start\")\n",
        "drop_if_exists(df_sentences, \"scene_number_end\")\n",
        "\n",
        "# Insert columns for metric_2_score and scene_number\n",
        "df_sentences.insert(1, \"metric_2_score\", 0)\n",
        "df_sentences.insert(1, \"scene_number_end\", 0)\n",
        "df_sentences.insert(1, \"scene_number_start\", 0)\n",
        "\n",
        "\n",
        "if not skip_text_metrics:\n",
        "  # Apply the function to get the score and scene_number\n",
        "  df_sentences[['metric_2_score', 'scene_number_start', 'scene_number_end']] = df_sentences.apply(compute_sentence_score, axis=1, result_type='expand')\n",
        "\n",
        "  df_sentences['scene_number_start'] = df_sentences['scene_number_start'].astype(int)\n",
        "  df_sentences['scene_number_end'] = df_sentences['scene_number_end'].astype(int)\n",
        "\n",
        "# Replace sentences_df with scenes\n",
        "else:\n",
        "  print_info(\"Metric 1 Skipped Defaulting to Metric 2-only evaluation...\")\n",
        "\n",
        "  df_scenes_as_sentences = df_scenes.assign(\n",
        "      base_idx=df_scenes.index,\n",
        "      scene_number_start=df_scenes.index,\n",
        "      scene_number_end=df_scenes.index,\n",
        "      metric_1_score=0,\n",
        "      metric_2_score=df_scenes.score,\n",
        "      start_time=df_scenes.start_time,\n",
        "      end_time=df_scenes.end_time,\n",
        "      sentence= \"\"\n",
        "  )\n",
        "\n",
        "  df_sentences = df_scenes_as_sentences\n",
        "\n",
        "  # only select columns from df_sentences\n",
        "  # df_scenes_as_sentences = df_scenes_as_sentences[df_sentences.columns]\n",
        "  # df_sentences = pd.concat([df_sentences, df_scenes_as_sentences], ignore_index=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "notebook_mode_print(df_sentences)"
      ],
      "metadata": {
        "id": "T0aw_xilNbxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Score - Metric Weighting"
      ],
      "metadata": {
        "id": "f2_bfRpGDxP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized Weigthed average\n",
        "w1 = hyperparameters['metric_1']['weight'] if not skip_text_metrics else 0\n",
        "w2 = hyperparameters['metric_2']['weight']\n",
        "weight_sum = w1 + w2\n",
        "w1_normalized = w1 / weight_sum\n",
        "w2_normalized = w2 / weight_sum\n",
        "\n",
        "# Metric 1 Apply\n",
        "drop_if_exists(df_sentences, \"metric_1_weighted\")\n",
        "df_sentences.insert(0, \"metric_1_weighted\", 1)\n",
        "df_sentences['metric_1_score'] = df_sentences['metric_1_score'].astype(float)\n",
        "\n",
        "df_sentences['metric_1_weighted'] = w1_normalized * df_sentences['metric_1_score']\n",
        "\n",
        "# Metric 2 Apply\n",
        "drop_if_exists(df_sentences, \"metric_2_weighted\")\n",
        "df_sentences.insert(0, \"metric_2_weighted\", 1)\n",
        "df_sentences['metric_2_score'] = df_sentences['metric_2_score'].astype(float)\n",
        "\n",
        "df_sentences['metric_2_weighted'] = w2_normalized * df_sentences['metric_2_score']\n",
        "\n",
        "\n",
        "# Metric Final Apply\n",
        "drop_if_exists(df_sentences, \"metric_final\")\n",
        "df_sentences.insert(0, \"metric_final\", 1)\n",
        "\n",
        "df_sentences['metric_final'] = df_sentences['metric_1_weighted'] + df_sentences['metric_2_weighted']\n",
        "df_sentences[\"metric_final\"] = df_sentences[\"metric_final\"].round(2)\n",
        "\n",
        "\n",
        "\n",
        "# Reorder\n",
        "df_sentences = df_sentences[[\n",
        "    'metric_final',\n",
        "    'metric_1_weighted',\n",
        "    'metric_1_score',\n",
        "    'metric_2_weighted',\n",
        "    'metric_2_score',\n",
        "    'scene_number_start',\n",
        "    'scene_number_end',\n",
        "    'base_idx',\n",
        "    'start_time',\n",
        "    'end_time',\n",
        "    'sentence'\n",
        "    ]].copy()\n",
        "\n",
        "notebook_mode_print(df_sentences)"
      ],
      "metadata": {
        "id": "69OugA4Q7ACk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deletion Metric"
      ],
      "metadata": {
        "id": "30WvxFDDY4DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold\n",
        "threshold = hyperparameters['deletion_metric']['threshold']\n",
        "\n",
        "# Percentage\n",
        "percentile = df_sentences['metric_final'].quantile(threshold)\n",
        "filtered_df_to_keep = df_sentences[df_sentences['metric_final'] >= percentile]\n",
        "filtered_df_to_delete = df_sentences[df_sentences['metric_final'] < percentile]\n",
        "\n",
        "# Timestamps\n",
        "# sample_timestamps = [('00:00:00.00','00:00:01.25'), ('00:00:08.766', '00:00:11.042')]\n",
        "sentence_timestamps = list(zip(filtered_df_to_keep['start_time'], filtered_df_to_keep['end_time']))\n",
        "\n",
        "\n",
        "notebook_mode_print(sentence_timestamps)"
      ],
      "metadata": {
        "id": "o0u3xmx1Y0BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_text_metrics:\n",
        "  threshold = hyperparameters['deletion_metric']['threshold']\n",
        "\n",
        "  filtered_df = df_sentences.copy()\n",
        "\n",
        "  # Count words of each sentence\n",
        "  filtered_df['word_count'] = filtered_df['sentence'].apply(count_words_without_punctuation)\n",
        "\n",
        "  # Target word count to keep (e.g., 80% of total words when threshold = 20%)\n",
        "  total_word_count = filtered_df['word_count'].sum()\n",
        "  target_word_count = round(total_word_count * (1 - threshold))\n",
        "\n",
        "  # Sort the DataFrame by 'metric_final' (low to high score)\n",
        "  filtered_df = filtered_df.sort_values(by='metric_final')\n",
        "\n",
        "  # Initialize the variable for the current word count of remaining sentences\n",
        "  current_word_count = total_word_count\n",
        "\n",
        "  # Create a new column for keeping/deleting sentences\n",
        "  filtered_df[\"threshold_keep\"] = 1  # Default to keeping all sentences\n",
        "\n",
        "  # Iteratively mark sentences for deletion until the target word count is reached\n",
        "  for idx, row in filtered_df.iterrows():\n",
        "      # if current_word_count <= target_word_count: # deleting 1 more\n",
        "      if current_word_count - row[\"word_count\"]<= target_word_count: # deleting 1 less\n",
        "          break  # Stop once we've removed enough words\n",
        "\n",
        "      # Update the current word count after marking the sentence\n",
        "      current_word_count -= row[\"word_count\"]\n",
        "\n",
        "      # Mark sentence for deletion\n",
        "      filtered_df.at[idx, \"threshold_keep\"] = 0  # 0 = delete, 1 = keep\n",
        "\n",
        "  # Restore sort\n",
        "  filtered_df = filtered_df.sort_values(by='base_idx')\n",
        "\n",
        "  # Text to keep/delete\n",
        "  filtered_df_to_delete = filtered_df[filtered_df['threshold_keep'] == 0].copy()\n",
        "  filtered_df_to_keep = filtered_df[filtered_df['threshold_keep'] == 1].copy()\n",
        "\n",
        "  # Timestamps\n",
        "  sentence_timestamps = list(zip(filtered_df_to_keep['start_time'], filtered_df_to_keep['end_time']))\n",
        "\n",
        "\n",
        "  notebook_mode_print(filtered_df)"
      ],
      "metadata": {
        "id": "bFukchyJCWcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Keep"
      ],
      "metadata": {
        "id": "CbPmShbOAOKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_mode_print(filtered_df_to_keep[['metric_final', 'start_time', 'end_time', 'sentence']])"
      ],
      "metadata": {
        "id": "Lc6rNol2AMEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_keep = \" \".join(filtered_df_to_keep['sentence'].tolist())\n",
        "paragraph_trimmed = text_to_keep\n",
        "\n",
        "notebook_mode_print(text_to_keep)"
      ],
      "metadata": {
        "id": "GZxDdCruWMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Delete"
      ],
      "metadata": {
        "id": "527IGciIVE-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_mode_print(filtered_df_to_delete[['metric_final', 'start_time', 'end_time', 'sentence']])"
      ],
      "metadata": {
        "id": "aXeKSTFUVAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_delete = \" \".join(filtered_df_to_delete['sentence'].tolist())\n",
        "\n",
        "notebook_mode_print(text_to_delete)"
      ],
      "metadata": {
        "id": "ZBibL8nfWUuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not skip_text_metrics:\n",
        "  words_kept = filtered_df_to_keep['word_count'].sum()\n",
        "  words_delete = filtered_df_to_delete['word_count'].sum()\n",
        "\n",
        "  notebook_mode_print(f\"Text deletion: {round(words_delete/(words_kept+words_delete) * 100, 2)}%\")\n",
        "  notebook_mode_print(f\"Sentence deletion: {round(len(filtered_df_to_delete) / (len(filtered_df_to_delete) + len(filtered_df_to_keep)) * 100, 2)}%\")"
      ],
      "metadata": {
        "id": "244XAgn6BNlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PostProcessing"
      ],
      "metadata": {
        "id": "xlckTwsoxVqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Time Taken: ~1.5min\n",
        "6min video: ~2min to process, ~30sec to download"
      ],
      "metadata": {
        "id": "OeQG-f5ZWhPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_section(\"Postprocessing\")"
      ],
      "metadata": {
        "id": "A4pemnKZUvgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skim_video(input_video, output_video, segments_to_retain):\n",
        "    \"\"\"\n",
        "    Skims a video by keeping only the specified segments and removes others.\n",
        "\n",
        "    Args:\n",
        "        input_video (str): Path to the input video file.\n",
        "        output_video (str): Path to the output video file.\n",
        "        segments_to_retain (list of tuples): List of tuples where each tuple contains\n",
        "                                             (start_time, end_time) in seconds to retain.\n",
        "    \"\"\"\n",
        "    print_info(\"Processed video...\")\n",
        "\n",
        "    # Prepare the select filter for video (only select the specified ranges)\n",
        "    video_select_filter = '+'.join([\n",
        "        f\"between(t,{start},{end})\"\n",
        "        for start, end in segments_to_retain\n",
        "    ])\n",
        "\n",
        "    # Prepare the select filter for audio (only select the specified ranges)\n",
        "    audio_select_filter = '+'.join([\n",
        "        f\"between(t,{start},{end})\"\n",
        "        for start, end in segments_to_retain\n",
        "    ])\n",
        "\n",
        "    # Construct the ffmpeg command with the specified filters\n",
        "    ffmpeg_command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-i\", input_video,\n",
        "        \"-vf\", f\"select='{video_select_filter}',setpts=N/FRAME_RATE/TB\",\n",
        "        \"-af\", f\"aselect='{audio_select_filter}',asetpts=N/SR/TB\",\n",
        "        \"-threads\", str(os.cpu_count()),\n",
        "         \"-preset\", \"ultrafast\",\n",
        "        output_video\n",
        "    ]\n",
        "\n",
        "    # Run the FFmpeg command and capture the output\n",
        "    result = subprocess.run(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Check if FFmpeg finished successfully or if there were errors\n",
        "    if result.returncode != 0:\n",
        "        print(\"FFmpeg Error:\")\n",
        "        print(result.stderr.decode())  # Print the error output\n",
        "    else:\n",
        "        print_info(\"Video processed successfully.\")"
      ],
      "metadata": {
        "id": "NfISPooMSZts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_length(input_video):\n",
        "    \"\"\"Get the duration (length) of a video file using ffmpeg-python.\"\"\"\n",
        "    probe = ffmpeg.probe(input_video, v='error', select_streams='v:0', show_entries='format=duration')\n",
        "    return float(probe['format']['duration'])"
      ],
      "metadata": {
        "id": "dF2SauF8OsQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_keep_timestamps(timestamps_to_remove, video_length=None):\n",
        "    \"\"\"\n",
        "    Given a list of timestamps to remove from a video, generates the list of timestamps to keep.\n",
        "\n",
        "    Args:\n",
        "        timestamps_to_remove (list of tuples): List of segments to remove (start_time, end_time) in seconds.\n",
        "        video_length (float, optional): Total length of the video in seconds. If not provided, the last segment's end is used.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: Segments to keep.\n",
        "    \"\"\"\n",
        "    # Sort the timestamps to remove by their start times (just in case they're out of order)\n",
        "    timestamps_to_remove.sort()\n",
        "\n",
        "    # Initialize the list of segments to keep\n",
        "    timestamps = []\n",
        "\n",
        "    # If the first removal starts after 0, keep from the start of the video to the first removal\n",
        "    if timestamps_to_remove[0][0] > 0:\n",
        "        timestamps.append((0.0, timestamps_to_remove[0][0]))\n",
        "\n",
        "    # Now, for each consecutive pair of timestamps to remove, keep the time between them\n",
        "    for i in range(len(timestamps_to_remove) - 1):\n",
        "        end_of_previous_removal = timestamps_to_remove[i][1]\n",
        "        start_of_next_removal = timestamps_to_remove[i + 1][0]\n",
        "\n",
        "        # If there's a gap, keep that gap\n",
        "        if end_of_previous_removal < start_of_next_removal:\n",
        "            timestamps.append((end_of_previous_removal, start_of_next_removal))\n",
        "\n",
        "    # If there is time left after the last removal, keep it\n",
        "    if video_length is not None:\n",
        "        last_end_time = timestamps_to_remove[-1][1]\n",
        "        if last_end_time < video_length:\n",
        "            timestamps.append((last_end_time, video_length))\n",
        "\n",
        "    return timestamps"
      ],
      "metadata": {
        "id": "inh8KX0HPYHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Timestamp pre-processing\n",
        "original_video_length = get_video_length(video_input)\n",
        "\n",
        "# Dev mode: export shorter video\n",
        "video_length = min(original_video_length, video_export_max_length_seconds) if video_export_max_length_seconds > 0 else original_video_length\n",
        "\n",
        "# Trim Method 1: Video with sentences to remove, removed\n",
        "# timestamps_to_remove = list(map(lambda x: (ts_to_s(x[0]), ts_to_s(x[1])), sentence_timestamps))\n",
        "# timestamps_to_keep = generate_keep_timestamps(timestamps_to_remove, video_length)\n",
        "\n",
        "# Trim method 2: Video of only sentences to keep\n",
        "timestamps_to_keep = list(map(lambda x: (ts_to_s(x[0]), ts_to_s(x[1])), sentence_timestamps))\n",
        "\n",
        "# print(f\"Timestamps to remove: {timestamps_to_remove}\")\n",
        "notebook_mode_print(f\"Timestamps to keep: {timestamps_to_keep}\")"
      ],
      "metadata": {
        "id": "v0Ep0aI4utT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skim Video\n",
        "if not experiment_mode:\n",
        "  skim_video(video_input, video_output_skimmed, timestamps_to_keep)"
      ],
      "metadata": {
        "id": "UI8mxQGpSqH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "if not experiment_mode:\n",
        "  if notebook_mode:\n",
        "    print_info(\"Downloading video...\")\n",
        "    files.download(video_output_skimmed)"
      ],
      "metadata": {
        "id": "podJgk5bV0ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export original text\n",
        "if export_original_text:\n",
        "  paragraph_to_file(paragraph, filename_paragraph_original)\n",
        "\n",
        "  if notebook_mode:\n",
        "    files.download(filename_paragraph_original)\n",
        "\n",
        "# Export trimmed text\n",
        "if export_trimmed_text:\n",
        "  paragraph_to_file(paragraph_trimmed, filename_paragraph_trimmed)\n",
        "\n",
        "  if notebook_mode:\n",
        "    files.download(filename_paragraph_trimmed)\n",
        "\n",
        "# Export summarized text\n",
        "if export_summarized_text:\n",
        "  paragraph_to_file(paragraph_summarized, filename_paragraph_summarized)\n",
        "\n",
        "  if notebook_mode:\n",
        "    files.download(filename_paragraph_summarized)"
      ],
      "metadata": {
        "id": "ZImZWrzf51wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Metrics\n",
        "if not experiment_mode:\n",
        "  print_section(\"Simple Metrics\")\n",
        "\n",
        "  original_video_length = get_video_length(video_input)\n",
        "  print(f\"Original Video Length: {original_video_length:.2f}s\\n\")\n",
        "\n",
        "  skimmed_video_length = get_video_length(video_output_skimmed)\n",
        "  print(f\"Skimmed Video Length: {skimmed_video_length:.2f}s\\n\")\n",
        "\n",
        "  summarization_ratio = (original_video_length - skimmed_video_length) / original_video_length\n",
        "  print(f\"Skimmed/Original Video Length Ratio: {summarization_ratio:.2f}\")"
      ],
      "metadata": {
        "id": "D1IT6bosV3Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment Export"
      ],
      "metadata": {
        "id": "34Krt8NbAG9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if experiment_mode:\n",
        "  df_sentences[['metric_final', 'start_time', 'end_time', 'base_idx', 'sentence']].to_csv(filename_experiment_sentences, index=False)\n",
        "\n",
        "  with open(filename_experiment_hyperparameters, \"w\") as f:\n",
        "    json.dump(hyperparameters, f, indent=2)\n",
        "\n",
        "  print_info(\"Experiment files exported.\")"
      ],
      "metadata": {
        "id": "bTusUt0BAEwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}